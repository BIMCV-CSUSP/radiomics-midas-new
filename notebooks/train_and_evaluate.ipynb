{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92166e6a",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c556bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from scipy.stats import shapiro, mannwhitneyu, ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, f1_score, precision_score,\n",
    "                             recall_score, balanced_accuracy_score, cohen_kappa_score,\n",
    "                             matthews_corrcoef, confusion_matrix)\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import label_binarize\n",
    "mpl.use('Agg')\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science', 'grid'])\n",
    "dpi = 300\n",
    "from scipy.stats import kruskal, f_oneway\n",
    "plt.rcParams[\"text.usetex\"] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84a118bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(random_state=42):\n",
    "    \"\"\"\n",
    "    Define los pipelines para cada clasificador, incluyendo preprocesamiento estándar.\n",
    "    \n",
    "    Args:\n",
    "        random_state (int): Semilla para reproducibilidad\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de tuplas (nombre_modelo, pipeline_scikit)\n",
    "    \"\"\"\n",
    "\n",
    "    # Pipeline para Support Vector Machine\n",
    "    pipe_svc = make_pipeline(\n",
    "        StandardScaler(), # Normalización de características\n",
    "        VarianceThreshold(),  # Eliminación de características con varianza nula\n",
    "        SVC(random_state=random_state, class_weight=\"balanced\", probability=True)\n",
    "    )\n",
    "    \n",
    "    # Pipeline para Regresión Logística\n",
    "    pipe_lr = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        VarianceThreshold(),\n",
    "        LogisticRegression(\n",
    "            penalty='elasticnet',       # Regularización combinada L1 y L2\n",
    "            l1_ratio=0.5,               # Ratio para elasticnet (0.5 = igual peso L1 y L2)\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=random_state,\n",
    "            solver='saga',              # Optimizador para elasticnet\n",
    "            max_iter=10000              # Iteraciones máximas\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Pipeline para Random Forest\n",
    "    pipe_rf = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        VarianceThreshold(),\n",
    "        RandomForestClassifier(n_jobs=-1, class_weight=\"balanced_subsample\", random_state=random_state)\n",
    "    )\n",
    "    \n",
    "    # Pipeline para Naive Bayes Gaussiano\n",
    "    pipe_nb = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        VarianceThreshold(),\n",
    "        GaussianNB() # No necesita parámetros adicionales\n",
    "    )\n",
    "    \n",
    "    # Pipeline para K-Nearest Neighbors\n",
    "    pipe_knn = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        VarianceThreshold(),\n",
    "        KNeighborsClassifier(n_jobs=-1)\n",
    "    )\n",
    "    \n",
    "    # Pipeline para Gradient Boosting\n",
    "    pipe_gb = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        VarianceThreshold(),\n",
    "        GradientBoostingClassifier(random_state=random_state)\n",
    "    )\n",
    "\n",
    "    # Lista con todos los modelos\n",
    "    models = [\n",
    "        (\"SVM\", pipe_svc),\n",
    "        (\"Logistic Regression\", pipe_lr),\n",
    "        (\"Random Forest\", pipe_rf),\n",
    "        (\"Naive Bayes\", pipe_nb),\n",
    "        (\"KNN\", pipe_knn),\n",
    "        (\"Gradient Boosting\", pipe_gb),\n",
    "    ]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d08bf9",
   "metadata": {},
   "source": [
    "# Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd44644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_multiclass(model, X, y, groups, n_splits=5, n_repeats=1, base_random_state=42):\n",
    "    \"\"\"\n",
    "    Realiza validación cruzada repetida estratificada por grupos (multiclase).\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo a evaluar (pipeline de scikit-learn)\n",
    "        X (pd.DataFrame): Características\n",
    "        y (np.array): Etiquetas multiclase\n",
    "        groups (np.array): Identificadores de grupos (pacientes) para CV\n",
    "        n_splits (int): Número de particiones por repetición\n",
    "        n_repeats (int): Número de repeticiones de la validación cruzada\n",
    "        base_random_state (int): Semilla base para reproducibilidad\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (fold_results, pred_vals)\n",
    "            - fold_results: Lista de diccionarios con métricas por fold\n",
    "            - pred_vals: Dict con datos de predicciones para cada fold\n",
    "    \"\"\"\n",
    "    fold_results = []\n",
    "    folds_data = []\n",
    "    global_fold_index = 0\n",
    "    classes = np.unique(y)\n",
    "    for rep in range(n_repeats):\n",
    "        current_random_state = base_random_state + rep\n",
    "        splitter = StratifiedGroupKFold(\n",
    "            n_splits=n_splits, shuffle=True, random_state=current_random_state\n",
    "        )\n",
    "        for train_idx, val_idx in splitter.split(X, y, groups=groups):\n",
    "            global_fold_index += 1\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            model.fit(X_train, y_train)\n",
    "            y_train_pred = model.predict(X_train)\n",
    "\n",
    "            # Probabilidades o scores\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_train_prob = model.predict_proba(X_train)\n",
    "            elif hasattr(model, \"decision_function\"):\n",
    "                y_train_prob = model.decision_function(X_train)\n",
    "            else:\n",
    "                y_train_prob = None\n",
    "\n",
    "            # AUC multiclase en entrenamiento\n",
    "            try:\n",
    "                y_train_bin = label_binarize(y_train, classes=classes)\n",
    "                if y_train_prob is not None and len(np.unique(y_train)) > 1:\n",
    "                    train_auc = roc_auc_score(y_train_bin, y_train_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "                else:\n",
    "                    train_auc = np.nan\n",
    "            except:\n",
    "                train_auc = np.nan\n",
    "\n",
    "            train_f1_macro = f1_score(y_train, y_train_pred, average=\"macro\")\n",
    "\n",
    "            # Validación\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_val_prob = model.predict_proba(X_val)\n",
    "            elif hasattr(model, \"decision_function\"):\n",
    "                y_val_prob = model.decision_function(X_val)\n",
    "            else:\n",
    "                y_val_prob = None\n",
    "\n",
    "            # AUC multiclase en validación\n",
    "            try:\n",
    "                y_val_bin = label_binarize(y_val, classes=classes)\n",
    "                if y_val_prob is not None and len(np.unique(y_val)) > 1:\n",
    "                    val_auc = roc_auc_score(y_val_bin, y_val_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "                else:\n",
    "                    val_auc = np.nan\n",
    "            except:\n",
    "                val_auc = np.nan\n",
    "\n",
    "            val_mcc = matthews_corrcoef(y_val, y_val_pred)\n",
    "            val_kappa = cohen_kappa_score(y_val, y_val_pred)\n",
    "            val_f1_macro = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "            val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "            val_balanced_accuracy = balanced_accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "            # Métricas por clase\n",
    "            per_class_precision = precision_score(y_val, y_val_pred, average=None, labels=classes)\n",
    "            per_class_recall = recall_score(y_val, y_val_pred, average=None, labels=classes)\n",
    "            per_class_f1 = f1_score(y_val, y_val_pred, average=None, labels=classes)\n",
    "\n",
    "            # Matriz de confusión y exactitud por clase\n",
    "            cm = confusion_matrix(y_val, y_val_pred, labels=classes)\n",
    "            per_class_accuracy = []\n",
    "            for i in range(len(cm)):\n",
    "                row_sum = np.sum(cm[i, :])\n",
    "                if row_sum > 0:\n",
    "                    per_class_accuracy.append(cm[i, i] / row_sum)\n",
    "                else:\n",
    "                    per_class_accuracy.append(np.nan)\n",
    "\n",
    "            fold_metrics = {\n",
    "                \"Fold\": global_fold_index,\n",
    "                \"Repeat\": rep + 1,\n",
    "                \"train_auc\": train_auc,\n",
    "                \"train_f1_macro\": train_f1_macro,\n",
    "                \"val_auc\": val_auc,\n",
    "                \"val_mcc\": val_mcc,\n",
    "                \"val_kappa\": val_kappa,\n",
    "                \"val_f1_macro\": val_f1_macro,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "                \"val_balanced_accuracy\": val_balanced_accuracy,\n",
    "                \"per_class_precision\": per_class_precision.tolist(),\n",
    "                \"per_class_recall\": per_class_recall.tolist(),\n",
    "                \"per_class_f1\": per_class_f1.tolist(),\n",
    "                \"per_class_accuracy\": per_class_accuracy\n",
    "            }\n",
    "            fold_results.append(fold_metrics)\n",
    "\n",
    "            folds_data.append({\n",
    "                \"fold_index\": global_fold_index,\n",
    "                \"Repeat\": rep + 1,\n",
    "                \"y_val\": y_val,\n",
    "                \"y_val_pred\": y_val_pred,\n",
    "                \"y_val_prob\": y_val_prob\n",
    "            })\n",
    "\n",
    "    pred_vals = {\n",
    "        \"folds\": folds_data\n",
    "    }\n",
    "    return fold_results, pred_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f59dae",
   "metadata": {},
   "source": [
    "# Código principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef987c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Función principal que coordina el proceso completo de entrenamiento y evaluación:\n",
    "1. Procesa argumentos de línea de comandos\n",
    "2. Carga y preprocesa los datos\n",
    "3. Realiza selección de características (opcional)\n",
    "4. Entrena y evalúa modelos\n",
    "5. Genera curvas ROC y resultados\n",
    "6. Ejecuta scripts complementarios (opcional)\n",
    "\"\"\"\n",
    "# --- Configuración de argumentos de línea de comandos ---    \n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Evaluación de modelos con validación cruzada repetida\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--csv\", type=str,\n",
    "    choices=[\"features_all_gland.csv\", \"features_all_full.csv\"],\n",
    "    default=\"features_all_gland.csv\",\n",
    "    help=\"Nombre del CSV con las características.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--data_pre\", type=str,\n",
    "    default=\"../../../artifacts/radiomics\",\n",
    "    help=\"Directorio raíz donde se encuentran los datos radiomics.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--results_base\", type=str, default=\"../../../results/radiomics\",\n",
    "    help=\"Directorio base donde se crearán los resultados.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n_splits\", type=int, default=5,\n",
    "    help=\"Número de particiones para StratifiedGroupKFold (por repetición).\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n_repeats\", type=int, default=10,\n",
    "    help=\"Número de repeticiones de la validación cruzada.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--feature_strategy\", type=str,\n",
    "    choices=[\"all\", \"most_discriminant\"],\n",
    "    default=\"most_discriminant\",\n",
    "    help=\"Estrategia de selección de features: 'all' o 'most_discriminant'.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--calculate_differences\", action=\"store_true\", default=True,\n",
    "    help=\"Si se habilita, ejecuta model_differences.py.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--fine_tune_best_model\", action=\"store_true\", default=False,\n",
    "    help=\"Si se habilita, realiza fine-tuning del mejor modelo.\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f0b6d",
   "metadata": {},
   "source": [
    "# Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc23af06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creada carpeta de resultados: /mnt/datalake/openmind/MedP-Midas/data/features_t2w\n"
     ]
    }
   ],
   "source": [
    "# --- Carga de datos y preprocesamiento ---\n",
    "label_csv= \"label1\" \n",
    "num_label = label_csv[-1]\n",
    "df = pd.read_csv(f'/mnt/datalake/openmind/MedP-Midas/data/features_t2w/features_t2w_{label_csv}_with_pfirrmann.csv')\n",
    "y = df[f\"{num_label}\"]\n",
    "groups = df[\"patient_id\"]\n",
    "X = df.drop([ 'patient_id','1', '2', '3', '4', '5','study_id', 'label', 'mask_type',\n",
    "                              'diagnostics_Versions_PyRadiomics', 'diagnostics_Versions_Numpy', \n",
    "                              'diagnostics_Versions_SimpleITK', 'diagnostics_Versions_PyWavelet', \n",
    "                              'diagnostics_Versions_Python', 'diagnostics_Configuration_Settings', \n",
    "                              'diagnostics_Configuration_EnabledImageTypes', 'diagnostics_Image-original_Hash', \n",
    "                              'diagnostics_Image-original_Dimensionality', 'diagnostics_Image-original_Spacing', \n",
    "                              'diagnostics_Image-original_Size', 'diagnostics_Image-original_Mean', \n",
    "                              'diagnostics_Image-original_Minimum', 'diagnostics_Image-original_Maximum', \n",
    "                              'diagnostics_Mask-original_Hash', 'diagnostics_Mask-original_Spacing', \n",
    "                              'diagnostics_Mask-original_Size', 'diagnostics_Mask-original_BoundingBox', \n",
    "                              'diagnostics_Mask-original_VoxelNum', 'diagnostics_Mask-original_VolumeNum', \n",
    "                              'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Mask-original_CenterOfMass', \n",
    "                              'diagnostics_Image-interpolated_Spacing', 'diagnostics_Image-interpolated_Size', \n",
    "                              'diagnostics_Image-interpolated_Mean', 'diagnostics_Image-interpolated_Minimum', \n",
    "                              'diagnostics_Image-interpolated_Maximum', 'diagnostics_Mask-interpolated_Spacing', \n",
    "                              'diagnostics_Mask-interpolated_Size', 'diagnostics_Mask-interpolated_BoundingBox', \n",
    "                              'diagnostics_Mask-interpolated_VoxelNum', 'diagnostics_Mask-interpolated_VolumeNum', \n",
    "                              'diagnostics_Mask-interpolated_CenterOfMassIndex', 'diagnostics_Mask-interpolated_CenterOfMass', \n",
    "                              'diagnostics_Mask-interpolated_Mean', 'diagnostics_Mask-interpolated_Minimum', \n",
    "                              'diagnostics_Mask-interpolated_Maximum',], axis=1)\n",
    "\n",
    "experiment_dir = \"/mnt/datalake/openmind/MedP-Midas/data/features_t2w\"\n",
    "os.makedirs(experiment_dir, exist_ok=True)\n",
    "print(f\"Creada carpeta de resultados: {experiment_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df021b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Realizando selección de características...\n",
      "  --> Seleccionadas 48 características más relevantes.\n",
      "  --> Guardado CSV: /mnt/datalake/openmind/MedP-Midas/data/features_t2w/feature_selection/train_auc_pvals_dflabel1.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Selección de características ---\n",
    "selected_features = X.columns\n",
    "\n",
    "if args.feature_strategy == \"most_discriminant\":\n",
    "    print(\">> Realizando selección de características...\")\n",
    "\n",
    "    # Directorios para resultados de selección de características\n",
    "    fs_dir = os.path.join(experiment_dir, \"feature_selection\")\n",
    "    os.makedirs(fs_dir, exist_ok=True)\n",
    "    images_dir = os.path.join(fs_dir, f\"images{label_csv}\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "    # Inicializar listas para almacenar estadísticas por característica\n",
    "    feature_names, test_type_list, pvalue_list = ([] for _ in range(3))\n",
    "\n",
    "    # Evaluar cada característica individualmente\n",
    "    for column in X.columns:\n",
    "        stat, p = shapiro(X[column])\n",
    "        grupos = [X[column][y == clase] for clase in np.unique(y)]\n",
    "        feature_names.append(column)\n",
    "        alpha = 0.05\n",
    "        if p > alpha:\n",
    "            test_type_list.append('ANOVA')\n",
    "            stats, pval = f_oneway(*grupos)\n",
    "        else:\n",
    "            test_type_list.append('Kruskal-Wallis')\n",
    "            stats, pval = kruskal(*grupos)\n",
    "        pvalue_list.append(pval)\n",
    "\n",
    "    # Crear DataFrame con todas las estadísticas por característica\n",
    "    train_auc_pvals_df = pd.DataFrame(\n",
    "        list(zip(test_type_list, pvalue_list)),\n",
    "        index=feature_names,\n",
    "        columns=['Test', 'p-value']\n",
    "    ).sort_values(by='p-value', ascending=True)\n",
    "\n",
    "    # Seleccionar características: máximo 1 característica por cada 15 muestras\n",
    "    num_features_model = round(X.shape[0] / 15)\n",
    "    train_df = train_auc_pvals_df.sort_values(by='p-value', ascending=True)\n",
    "\n",
    "    # Seleccionar las N características más significativas\n",
    "    selected_features = train_df.index[0:num_features_model]\n",
    "    print(f\"  --> Seleccionadas {len(selected_features)} características más relevantes.\")\n",
    "\n",
    "    # Filtrar DataFrame para usar solo las características seleccionadas\n",
    "    X = X[selected_features]\n",
    "    # Guardar DataFrame con estadísticas completas\n",
    "    df_path_1 = os.path.join(fs_dir, f\"train_auc_pvals_df{label_csv}.csv\")\n",
    "    train_auc_pvals_df.loc[selected_features].to_csv(df_path_1)\n",
    "    print(f\"  --> Guardado CSV: {df_path_1}\\n\")\n",
    "\n",
    "\n",
    "    # --- Generar visualizaciones para las TOP 20 características ---\n",
    "    top_20 = train_auc_pvals_df.index[:20]\n",
    "\n",
    "    for rank, feature_name in enumerate(top_20, start=1):\n",
    "        # Crear nombre de archivo\n",
    "        safe_feat_name = feature_name.replace(\"/\", \"_\")\n",
    "        feat_folder_name = f\"{rank}_{safe_feat_name}\"\n",
    "        feat_folder_path = os.path.join(images_dir, feat_folder_name)\n",
    "        os.mkdir(feat_folder_path)\n",
    "        \n",
    "        # 1. Gráfico de violín para visualizar distribuciones por clase\n",
    "        plt.figure(figsize=(9, 9))\n",
    "        sns.violinplot(x=y, y=df[feature_name], color='grey')\n",
    "        plt.title(f\"Distribución de {feature_name} por clase Pfirrmann\", fontsize=14)\n",
    "        plt.xlabel(\"Clase de Pfirrmann\")\n",
    "        plt.ylabel(feature_name)\n",
    "        violin_plot_path = os.path.join(feat_folder_path, f\"{safe_feat_name}_violinplot.png\")\n",
    "        plt.savefig(violin_plot_path, dpi=dpi)\n",
    "        plt.close()\n",
    "else:\n",
    "    print(\">> Usando TODAS las características (sin selección).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e351ef8",
   "metadata": {},
   "source": [
    "# Entrenamiento y evaluación modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f8d6fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando Naive Bayes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando KNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando Gradient Boosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/datalake/openmind/MedP-Midas/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados guardados en '/mnt/datalake/openmind/MedP-Midas/data/features_t2w/resultados_discoslumbar_label1.csv'\n",
      "Predicciones guardadas en '/mnt/datalake/openmind/MedP-Midas/data/features_t2w/preds_discoslumbar_label1.csv'\n",
      "Archivo con variables usadas: /mnt/datalake/openmind/MedP-Midas/data/features_t2w/variables_usadas_label1.txt\n"
     ]
    }
   ],
   "source": [
    "#--- Entrenamiento y evaluación de modelos ---\n",
    "models = get_models(random_state=42)\n",
    "\n",
    "# Colectores para resultados\n",
    "all_results = []\n",
    "preds_data = []\n",
    "\n",
    "# Evaluar cada modelo\n",
    "for model_name, model in models:\n",
    "    print(f\"Evaluando {model_name}...\")\n",
    "    fold_metrics_list, pred_vals = evaluate_model_multiclass(\n",
    "        model, X, y, groups,\n",
    "        n_splits=args.n_splits,\n",
    "        n_repeats=args.n_repeats,\n",
    "        base_random_state=42\n",
    "    )\n",
    "\n",
    "    # Añadir nombre de clasificador a cada resultado\n",
    "    for fold_metrics in fold_metrics_list:\n",
    "        fold_metrics[\"Classifier\"] = model_name\n",
    "        all_results.append(fold_metrics)\n",
    "\n",
    "    # Almacenar predicciones\n",
    "    preds_data.append({\n",
    "        \"Classifier\": model_name,\n",
    "        \"folds\": pred_vals[\"folds\"]\n",
    "    })\n",
    "\n",
    "# Crear DataFrame con todos los resultados\n",
    "df_resultados = pd.DataFrame(all_results)\n",
    "\n",
    "# Ordenar columnas para mejor legibilidad\n",
    "fixed_cols = [\"Classifier\", \"Fold\", \"Repeat\"]\n",
    "other_cols = [c for c in df_resultados.columns if c not in fixed_cols]\n",
    "df_resultados = df_resultados[fixed_cols + other_cols]\n",
    "df_resultados.sort_values(by=[\"Classifier\", \"Fold\"], inplace=True)\n",
    "\n",
    "# Generar nombre de archivo para resultados\n",
    "resultados_filename = f\"resultados_discoslumbar_label{num_label}.csv\"\n",
    "\n",
    "#Guardar resultados\n",
    "resultados_filepath = os.path.join(experiment_dir, resultados_filename)\n",
    "df_resultados.to_csv(resultados_filepath, index=False)\n",
    "print(f\"\\nResultados guardados en '{resultados_filepath}'\")\n",
    "\n",
    "\n",
    "# --- Estructurar datos de predicciones para guardar ---\n",
    "records_for_csv = []\n",
    "for item in preds_data:\n",
    "    clf_name = item[\"Classifier\"]\n",
    "    folds_info = item[\"folds\"]\n",
    "    for fold_info in folds_info:\n",
    "        fold_idx = fold_info[\"fold_index\"]\n",
    "        rep_idx = fold_info[\"Repeat\"]\n",
    "        \n",
    "        y_val_list = fold_info[\"y_val\"].tolist()\n",
    "        y_pred_list = fold_info[\"y_val_pred\"].tolist()\n",
    "        if fold_info[\"y_val_prob\"] is not None:\n",
    "            y_prob_list = fold_info[\"y_val_prob\"].tolist()\n",
    "        else:\n",
    "            y_prob_list = []\n",
    "        \n",
    "        records_for_csv.append({\n",
    "            \"Classifier\": clf_name,\n",
    "            \"Fold\": fold_idx,\n",
    "            \"Repeat\": rep_idx,\n",
    "            \"y_val\": y_val_list,\n",
    "            \"y_pred\": y_pred_list,\n",
    "            \"y_prob\": y_prob_list\n",
    "        })\n",
    "\n",
    "# Guardar predicciones en CSV\n",
    "df_preds = pd.DataFrame(records_for_csv)\n",
    "preds_filename = f\"preds_discoslumbar_label{num_label}.csv\"\n",
    "preds_filepath = os.path.join(experiment_dir, preds_filename)\n",
    "df_preds.to_csv(preds_filepath, index=False)\n",
    "print(f\"Predicciones guardadas en '{preds_filepath}'\")\n",
    "\n",
    "# --- Guardar lista de variables utilizadas ---\n",
    "variables_txt_path = os.path.join(experiment_dir, f\"variables_usadas_{label_csv}.txt\")\n",
    "with open(variables_txt_path, \"w\") as f:\n",
    "    for feat in selected_features:\n",
    "        f.write(str(feat) + \"\\n\")\n",
    "print(f\"Archivo con variables usadas: {variables_txt_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
